# Explainable Stock Screener

This repository contains a **production‑ready pipeline** for building an
explainable stock screener.  It fetches historical OHLCV data,
engineers a set of technical features, trains a
[LightGBM](https://lightgbm.readthedocs.io/) regression model and
provides both a command‑line interface and a web‑based UI (via
[Streamlit](https://streamlit.io/)) for ranking stocks and viewing the
reasons behind each prediction.

## Motivation

Predicting short‑term stock returns requires capturing non‑linear
patterns in price and volume data.  Ensemble tree methods such as
LightGBM are attractive because they handle large feature sets
efficiently and produce fast predictions.  Feature engineering is
critical: the model’s performance depends on input signals capturing
momentum, volatility and liquidity.  Recent work emphasises that
integrating **temporal, technical and sentiment‑based features** can
significantly improve predictive accuracy【583190237305002†L51-L57】.  LightGBM also
offers built‑in support for **SHAP** (Shapley additive explanations) via
the `predict_contrib` parameter: setting this flag produces
per‑feature contributions that show how each feature influences a
prediction【955532524344170†L1319-L1335】.  These contributions form the
foundation of the explanations presented in this project.

## Features and Labels

The feature set is kept deliberately small for clarity and ease of
extension.  For each ticker:

| Feature | Description |
| --- | --- |
| **momentum_1m** | One‑month price momentum: current close divided by the close 20 trading days ago minus 1 |
| **momentum_3m** | Three‑month momentum: current close divided by the close 60 trading days ago minus 1 |
| **momentum_6m** | Six‑month momentum: current close divided by the close 120 trading days ago minus 1 |
| **volatility_20d** | Realised volatility: standard deviation of daily log returns over the past 20 trading days |
| **volume_ratio_20d** | Liquidity proxy: current volume divided by its 20‑day moving average |

The **target** is the forward 20‑day return (`target_20d`), defined as
`(close_{t+20} / close_t) - 1`.  This target aligns with the model’s
objective of ranking stocks over the next ~20 trading days.

## Repository structure

```
explainable-screener/
├── data/
│   └── get_data.py      # Download raw data and compute features
├── models/
│   ├── model.txt        # Trained LightGBM model (generated by train.py)
│   └── feature_config.json  # Stores the list of feature columns used
├── utils/
│   └── feature_engineering.py  # Functions to compute momentum/volatility/liquidity features
├── train.py             # Train the LightGBM model using engineered features
├── predict.py           # Run the screener on a list of tickers
├── app.py               # Streamlit web application
├── requirements.txt     # Python dependencies
└── README.md            # This documentation
```

## Getting started

1. **Install dependencies** (preferably in a virtual environment):

   ```bash
   pip install -r requirements.txt
   ```

2. **Download data and compute features.**  Specify the tickers and
   date range you want to train on.  The example below downloads data
   from 2015 through 2025 for a basket of large‑cap US equities and
   writes a CSV of engineered features to `data/features.csv`.

   ```bash
   python data/get_data.py \
     --tickers "AAPL MSFT GOOGL AMZN META NVDA TSLA JNJ V WMT JPM PG UNH HD MA XOM PFE KO PEP" \
     --start 2015-01-01 \
     --end 2025-12-31 \
     --output data/features.csv
   ```

3. **Train the model.**  The training script loads the feature CSV,
   splits it chronologically (80% train / 20% validation), trains a
   LightGBM regressor and saves both the model and the feature
   configuration.  LightGBM is chosen because it handles large
   datasets efficiently and its built‑in `predict_contrib` option
   returns SHAP values for each feature【955532524344170†L1319-L1335】.

   ```bash
   python train.py --data data/features.csv --output_model models/model.txt --output_config models/feature_config.json
   ```

4. **Run the screener from the command line.**  You can generate
   rankings for a new set of tickers and view the top drivers of each
   prediction.  By default the script computes features using ~200
   calendar days of history (to cover six‑month momentum) ending on
   today’s date.

   ```bash
   python predict.py \
     --model models/model.txt \
     --config models/feature_config.json \
     --tickers "AAPL MSFT TSLA NVDA" \
     --top_k 3
   ```

   The output will look like:

   ```
    ticker  pred_return                                           reasons
      TSLA        0.032  momentum 3m (positive, 0.0185); momentum 6m (positive, 0.0123); volatility 20d (negative, -0.0032)
      NVDA        0.027  momentum 1m (positive, 0.0114); volume ratio 20d (positive, 0.0089); volatility 20d (negative, -0.0041)
      AAPL        0.015  momentum 6m (positive, 0.0067); momentum 3m (positive, 0.0052); momentum 1m (negative, -0.0010)
      MSFT        0.012  momentum 1m (positive, 0.0078); volume ratio 20d (positive, 0.0031); volatility 20d (negative, -0.0015)
   ```

   Each **reason** lists the most influential features driving the
   prediction along with the sign (positive/negative) and magnitude of
   their contribution.  These contributions come from LightGBM’s
   built‑in SHAP estimator and are returned via the `predict_contrib`
   flag【955532524344170†L1319-L1335】.

5. **Launch the Streamlit app.**  For an interactive UI, start
   Streamlit and explore the screener in your browser:

   ```bash
   streamlit run app.py
   ```

   The app lets you enter any set of Yahoo! Finance ticker symbols,
   choose date ranges and customise how many top features are shown.
   Results update automatically and display the predicted 20‑day
   returns alongside explanations.

## Extending the project

This repository is intentionally modular so you can customise it:

* **Add more features.**  The feature engineering code lives in
  `utils/feature_engineering.py`.  You could incorporate additional
  technical indicators (e.g., RSI, MACD), fundamental data or
  sentiment scores.  Research shows that combining temporal,
  technical and sentiment‑based features improves performance【583190237305002†L51-L57】.

* **Use alternative models.**  LightGBM is a strong baseline, but you
  might experiment with neural networks, linear models or
  classification objectives (e.g., predicting top/bottom quantiles).

* **Deploy the app.**  Streamlit apps can be deployed to many cloud
  platforms.  Ensure that environment variables contain your API
  keys if you decide to use premium data services.

## Notes and caveats

* **Data quality and survivorship bias.**  The example uses
  free Yahoo! Finance data, which may contain missing values or
  adjustment errors.  Consider cleaning data or using a premium
  provider for production use.

* **No financial advice.**  This project is for educational purposes
  and does not constitute investment advice.  Past performance is not
  indicative of future results.

## References

* **LightGBM documentation** – The `predict_contrib` parameter returns
  SHAP values (per‑feature contributions) when set to true【955532524344170†L1319-L1335】.
* **Feature engineering research** – Combining temporal, technical and
  sentiment features can boost prediction accuracy【583190237305002†L51-L57】.  The
  importance of advanced feature engineering in stock price prediction
  has been highlighted in recent academic studies【583190237305002†L118-L123】.
